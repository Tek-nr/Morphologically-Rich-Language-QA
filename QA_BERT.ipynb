{"cells":[{"cell_type":"code","execution_count":1,"id":"KodAbQn4tmVT","metadata":{"id":"KodAbQn4tmVT","executionInfo":{"status":"ok","timestamp":1717351318833,"user_tz":-180,"elapsed":392,"user":{"displayName":"Hilal N. Tek","userId":"15092988536956430744"}}},"outputs":[],"source":["#!pip install tensorflow==2.8.0\n","#!pip install transformers==4.16.0"]},{"cell_type":"code","execution_count":2,"id":"mGe31nw5sqrp","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14055,"status":"ok","timestamp":1717351332886,"user":{"displayName":"Hilal N. Tek","userId":"15092988536956430744"},"user_tz":-180},"id":"mGe31nw5sqrp","outputId":"93139dc0-2ef1-4668-be4d-bfca36d56f07"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers==4.37.2\n","  Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (3.14.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (0.23.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (2.31.0)\n","Collecting tokenizers<0.19,>=0.14 (from transformers==4.37.2)\n","  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.2) (2024.5.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.2) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.2) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.2) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.2) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.2) (2024.2.2)\n","Installing collected packages: tokenizers, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.19.1\n","    Uninstalling tokenizers-0.19.1:\n","      Successfully uninstalled tokenizers-0.19.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.41.1\n","    Uninstalling transformers-4.41.1:\n","      Successfully uninstalled transformers-4.41.1\n","Successfully installed tokenizers-0.15.2 transformers-4.37.2\n"]}],"source":["!pip install transformers==4.37.2"]},{"cell_type":"code","execution_count":3,"id":"5bfe0a89","metadata":{"id":"5bfe0a89","executionInfo":{"status":"ok","timestamp":1717351344610,"user_tz":-180,"elapsed":11726,"user":{"displayName":"Hilal N. Tek","userId":"15092988536956430744"}}},"outputs":[],"source":["import os\n","import re\n","import json\n","import string\n","import random\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tokenizers import BertWordPieceTokenizer\n","from transformers import BertTokenizer, TFBertModel, TFBertForSequenceClassification, BertConfig\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n","from keras.layers import Dropout\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense\n","from keras.layers import Activation, Dense\n","import transformers\n","\n","max_len = 512"]},{"cell_type":"code","execution_count":4,"id":"RQrzmoqxv4JV","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19614,"status":"ok","timestamp":1717351364209,"user":{"displayName":"Hilal N. Tek","userId":"15092988536956430744"},"user_tz":-180},"id":"RQrzmoqxv4JV","outputId":"22e53e5d-37cf-40a3-f159-655eea74dfbd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":5,"id":"de1gz7dTgcYT","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3367,"status":"ok","timestamp":1717351367574,"user":{"displayName":"Hilal N. Tek","userId":"15092988536956430744"},"user_tz":-180},"id":"de1gz7dTgcYT","outputId":"1d63e60b-aa38-4878-fa13-fdd4ea7009f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting jpype1\n","  Downloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (488 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.6/488.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from jpype1) (24.0)\n","Installing collected packages: jpype1\n","Successfully installed jpype1-1.5.0\n"]}],"source":["!pip install jpype1"]},{"cell_type":"code","execution_count":6,"id":"BHAoTqA35-kZ","metadata":{"id":"BHAoTqA35-kZ","executionInfo":{"status":"ok","timestamp":1717351371783,"user_tz":-180,"elapsed":4223,"user":{"displayName":"Hilal N. Tek","userId":"15092988536956430744"}}},"outputs":[],"source":["from jpype import startJVM, shutdownJVM, JClass, JString\n","\n","# Path to the Zemberek jar file\n","zemberek_jar_path = \"/content/drive/MyDrive/datasets/zemberek-full.jar\"\n","\n","# Check if the JAR file exists\n","if not os.path.exists(zemberek_jar_path):\n","    raise FileNotFoundError(f\"The specified JAR file path does not exist: {zemberek_jar_path}\")\n","\n","# Start the JVM with Zemberek\n","startJVM(\"-ea\", f\"-Djava.class.path={zemberek_jar_path}\")\n","\n","TurkishMorphology = JClass('zemberek.morphology.TurkishMorphology')\n","#WordAnalysis = JClass('zemberek.morphology.analysis.WordAnalysis')\n","\n","# Initialize the morphology object\n","morphology = TurkishMorphology.createWithDefaults()\n"]},{"cell_type":"code","execution_count":7,"id":"563fc411","metadata":{"id":"563fc411","executionInfo":{"status":"ok","timestamp":1717351371783,"user_tz":-180,"elapsed":3,"user":{"displayName":"Hilal N. Tek","userId":"15092988536956430744"}}},"outputs":[],"source":["# Set-up BERT tokenizer"]},{"cell_type":"code","execution_count":8,"id":"NL205o4CznB6","metadata":{"id":"NL205o4CznB6","executionInfo":{"status":"ok","timestamp":1717351371783,"user_tz":-180,"elapsed":3,"user":{"displayName":"Hilal N. Tek","userId":"15092988536956430744"}}},"outputs":[],"source":["path = \"/content/gdrive/MyDrive/TurkishQA/\"\n","models_path = path + \"models/\"\n","MODEL_NAME = \"dbmdz/bert-base-turkish-cased\""]},{"cell_type":"code","execution_count":9,"id":"4847d2be","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":276,"referenced_widgets":["ba3b33c00dd04d2e983a9152108b6a8c","507d06ed55a64e5fb98624a8b7523a70","9c929c2462e8466e9a999fea6ca40e54","f8536a5e632e46d09d41fb916a0cad6e","a4f68836ba9b48408562a3c94ceba09d","d3ac059ad8714efa8a84ea6395c498f8","dea8ab06d2a846d484ccca592edfe3c5","9964e4530dbf4fd1a537263b39c4e2ca","5892465d7b0142ccabe58cb7391eea61","35ff775f9a2c4c698ca0dbb36b7c693d","b595a422ad1b476a9460a5c6e735f40b","6740faa7bc0041f4ac89c0b9ace4fc5d","561a731a9fb544ebb0102d5bb3e75e1e","8d8e0588bf2640b4b656bb5abadc5cfd","46ab5f1e94c04e89a72ed4cf422323d0","a7f83b2252314695bb371e6d30b1701d","c95b4d13827245ddbe885507f1b0e157","88db124de63544ec9671fd854bd350e6","17d3ee5d34b84f0f8656263af6c2ae86","a007fa5bfc09404ab77dedf08c0bca39","1fa78b6c719148549710c465861cf865","427bd2ad174e42ee863c0fb03682fe7f","2293dbab60144a04a8471fc814b2d018","041157f9e4184cb5a6f04b557e63f733","3069157f38014d738501c28834d3e086","09017577a81048ddac414233ee56cdd6","9fdf5023acb547f9817b25daa0c0e750","9ff68601bdc0473f92775e6675ab569e","ecd86967ac83449382989de1b30336db","07612acc65374780b039050ef97ff343","fe45a6767aa547acab9d60c74361a8a0","5639b3906dbc464b91b176bf4ed55d63","37f9a36ab7514a519328085174b8dafa"]},"executionInfo":{"elapsed":2102,"status":"ok","timestamp":1717351373883,"user":{"displayName":"Hilal N. Tek","userId":"15092988536956430744"},"user_tz":-180},"id":"4847d2be","outputId":"1b07fa30-c32c-42db-899f-370b726c4a43"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba3b33c00dd04d2e983a9152108b6a8c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/251k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6740faa7bc0041f4ac89c0b9ace4fc5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2293dbab60144a04a8471fc814b2d018"}},"metadata":{}}],"source":["slow_tokenizer = BertTokenizer.from_pretrained(MODEL_NAME, do_lower_case=False)\n","splitted_model =  MODEL_NAME.split(\"/\")\n","save_path = models_path + splitted_model[0] + \"-\" + splitted_model[1] + \"/\"\n","\n","if not os.path.exists(save_path):\n","    os.makedirs(save_path)\n","\n","slow_tokenizer.save_pretrained(save_path)\n","tokenizer = BertWordPieceTokenizer(save_path + \"vocab.txt\", lowercase=False)"]},{"cell_type":"code","execution_count":10,"id":"77f9826f","metadata":{"id":"77f9826f","executionInfo":{"status":"ok","timestamp":1717351373883,"user_tz":-180,"elapsed":4,"user":{"displayName":"Hilal N. Tek","userId":"15092988536956430744"}}},"outputs":[],"source":["# Preprocess The Data"]},{"cell_type":"code","execution_count":11,"id":"676cfdfe","metadata":{"id":"676cfdfe","executionInfo":{"status":"ok","timestamp":1717351373883,"user_tz":-180,"elapsed":3,"user":{"displayName":"Hilal N. Tek","userId":"15092988536956430744"}}},"outputs":[],"source":["class TurkishSquadDataset:\n","    def __init__(self, question, context, start_char_idx, answer_text, all_answers):\n","        self.question = question\n","        self.context = context\n","        self.start_char_idx = int(start_char_idx)\n","        self.answer_text = answer_text\n","        self.all_answers = all_answers\n","        self.skip = False\n","\n","    def normalize_and_lemmatize(self, text):\n","        analysis = morphology.analyzeSentence(JString(text))\n","        result = []\n","        for word_analysis in analysis:\n","            lemmas = word_analysis.getLemmas()\n","            if lemmas:\n","                result.append(lemmas[0])\n","            else:\n","                result.append(word_analysis.getWord())\n","        return ' '.join(result)\n","\n","    def preprocess(self):\n","        context = self.context\n","        question = self.question\n","        answer_text = self.answer_text\n","        start_char_idx = self.start_char_idx\n","\n","        # Clean context, answer and question\n","        context = \" \".join(str(context).split())\n","        question = \" \".join(str(question).split())\n","        answer = \" \".join(str(answer_text).split())\n","\n","        # Find end character index of answer in context\n","        end_char_idx = start_char_idx + len(answer)\n","        if end_char_idx >= len(context):\n","            self.skip = True\n","            return\n","\n","        # Mark the character indexes in context that are in answer\n","        is_char_in_ans = [0] * len(context)\n","        for idx in range(start_char_idx, end_char_idx):\n","            is_char_in_ans[idx] = 1\n","\n","        # Tokenize context\n","        tokenized_context = tokenizer.encode(context)\n","\n","        # Find tokens that were created from answer characters\n","        ans_token_idx = []\n","        for idx, (start, end) in enumerate(tokenized_context.offsets):\n","            if sum(is_char_in_ans[start:end]) > 0:\n","                ans_token_idx.append(idx)\n","\n","        if len(ans_token_idx) == 0:\n","            self.skip = True\n","            return\n","\n","        # Find start and end token index for tokens from answer\n","        start_token_idx = ans_token_idx[0]\n","        end_token_idx = ans_token_idx[-1]\n","\n","        # Tokenize question\n","        tokenized_question = tokenizer.encode(question)\n","\n","        # Create inputs\n","        input_ids = tokenized_context.ids + tokenized_question.ids[1:]\n","        token_type_ids = [0] * len(tokenized_context.ids) + [1] * len(tokenized_question.ids[1:])\n","        attention_mask = [1] * len(input_ids)\n","\n","        # Pad and create attention masks.\n","        # Skip if truncation is needed\n","        padding_length = max_len - len(input_ids)\n","        if padding_length > 0:  # pad\n","            input_ids = input_ids + ([0] * padding_length)\n","            attention_mask = attention_mask + ([0] * padding_length)\n","            token_type_ids = token_type_ids + ([0] * padding_length)\n","        elif padding_length < 0:  # skip\n","            self.skip = True\n","            return\n","\n","        self.input_ids = input_ids\n","        self.token_type_ids = token_type_ids\n","        self.attention_mask = attention_mask\n","        self.start_token_idx = start_token_idx\n","        self.end_token_idx = end_token_idx\n","        self.context_token_to_char = tokenized_context.offsets"]},{"cell_type":"code","execution_count":12,"id":"26570077","metadata":{"id":"26570077","executionInfo":{"status":"ok","timestamp":1717351373883,"user_tz":-180,"elapsed":3,"user":{"displayName":"Hilal N. Tek","userId":"15092988536956430744"}}},"outputs":[],"source":["def read_json(dataset_path):\n","    with open(dataset_path, \"r\", encoding=\"utf-8\") as json_file:\n","        data = json.load(json_file)\n","    return data\n","\n","def json_to_list(json_dataset):\n","    dataset = []\n","    for item in json_dataset[\"data\"]:\n","        for paragraph in item[\"paragraphs\"]:\n","            context = paragraph[\"context\"]\n","            for qa in paragraph[\"qas\"]:\n","                question = qa[\"question\"]\n","                answer_text = qa[\"answers\"][0][\"text\"]\n","                all_answers = [answer[\"text\"] for answer in qa[\"answers\"]]\n","                start_char_idx = qa[\"answers\"][0][\"answer_start\"]\n","                dataset.append(TurkishSquadDataset(question, context, start_char_idx, answer_text, all_answers))\n","    print(\"Number of questions: \", len(dataset))\n","    return dataset\n","\n","def create_input_targets(dataset):\n","    dataset_dict = {\n","        \"input_ids\": [],\n","        \"token_type_ids\": [],\n","        \"attention_mask\": [],\n","        \"start_token_idx\": [],\n","        \"end_token_idx\": [],\n","    }\n","    for item in dataset:\n","        if not item.skip:\n","            for key in dataset_dict:\n","                dataset_dict[key].append(getattr(item, key))\n","\n","    for key in dataset_dict:\n","        dataset_dict[key] = np.array(dataset_dict[key])\n","\n","    x = [\n","        dataset_dict[\"input_ids\"],\n","        dataset_dict[\"token_type_ids\"],\n","        dataset_dict[\"attention_mask\"],\n","    ]\n","\n","    y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n","    return x, y\n","\n","def find_max_length(dataset):\n","    max_ = 0\n","    index = 0\n","    for i, element in enumerate(dataset):\n","        tokenized_question = tokenizer.encode(element.question)\n","        tokenized_context = tokenizer.encode(element.context)\n","        input_ids = tokenized_context.ids + tokenized_question.ids[1:]\n","\n","        if len(input_ids) > max_:\n","            max_ = len(input_ids)\n","            index = i\n","\n","    print(\"Max length: {}, Index: {}\".format(max_, index))\n","    return max_\n","\n","def train_test_split(dataset):\n","    random.shuffle(dataset)\n","    cut = int(len(dataset) * 0.1)\n","    train, test = dataset[:-cut], dataset[-cut:]\n","\n","    return train, test\n"]},{"cell_type":"code","execution_count":13,"id":"svraIbzW8XDE","metadata":{"id":"svraIbzW8XDE","executionInfo":{"status":"ok","timestamp":1717351373883,"user_tz":-180,"elapsed":3,"user":{"displayName":"Hilal N. Tek","userId":"15092988536956430744"}}},"outputs":[],"source":["def create_model():\n","    encoder = TFBertModel.from_pretrained(MODEL_NAME, output_hidden_states=True, output_attentions=True)\n","\n","    input_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n","    token_type_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"token_type_ids\")\n","    attention_mask = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n","\n","    embedding = encoder(\n","        input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask\n","    )[0]\n","\n","    start_logits = tf.keras.layers.Dense(1, name=\"start_logit\", use_bias=False)(embedding)\n","    start_logits = tf.keras.layers.Flatten()(start_logits)\n","\n","    end_logits = tf.keras.layers.Dense(1, name=\"end_logit\", use_bias=False)(embedding)\n","    end_logits = tf.keras.layers.Flatten()(end_logits)\n","\n","    start_probs = tf.keras.layers.Activation(tf.keras.activations.softmax, name=\"start_probs\")(start_logits)\n","    end_probs = tf.keras.layers.Activation(tf.keras.activations.softmax, name=\"end_probs\")(end_logits)\n","\n","    model = tf.keras.Model(\n","        inputs=[input_ids, token_type_ids, attention_mask],\n","        outputs=[start_probs, end_probs],\n","    )\n","\n","    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n","    model.compile(optimizer=optimizer, loss=[loss, loss])\n","\n","    return model"]},{"cell_type":"code","source":["def create_model_2():\n","    encoder = TFBertModel.from_pretrained(MODEL_NAME, output_hidden_states=True, output_attentions=True)\n","\n","    input_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32)\n","    token_type_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32)\n","    attention_mask = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32)\n","\n","    embedding = encoder(\n","        input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask\n","    )[0]\n","\n","    dropout = Dropout(0.1)(embedding)\n","    dense1 = Dense(256, activation='relu')(dropout)\n","    dropout1 = Dropout(0.1)(dense1)\n","    dense2 = Dense(128, activation='relu')(dropout1)\n","    dropout2 = Dropout(0.1)(dense2)\n","\n","    start_logits = tf.keras.layers.Dense(1, name=\"start_logit\", use_bias=False)(dropout)\n","    start_logits = tf.keras.layers.Flatten()(start_logits)\n","\n","    end_logits = tf.keras.layers.Dense(1, name=\"end_logit\", use_bias=False)(dropout)\n","    end_logits = tf.keras.layers.Flatten()(end_logits)\n","\n","    start_probs = tf.keras.layers.Activation(tf.keras.activations.softmax)(start_logits)\n","    end_probs = tf.keras.layers.Activation(tf.keras.activations.softmax)(end_logits)\n","\n","    model = tf.keras.Model(\n","        inputs=[input_ids, token_type_ids, attention_mask],\n","        outputs=[start_probs, end_probs],\n","    )\n","    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n","    model.compile(optimizer=optimizer, loss=[loss, loss])\n","    return model"],"metadata":{"id":"4JooE3cE2BvE","executionInfo":{"status":"ok","timestamp":1717351373883,"user_tz":-180,"elapsed":3,"user":{"displayName":"Hilal N. Tek","userId":"15092988536956430744"}}},"id":"4JooE3cE2BvE","execution_count":14,"outputs":[]},{"cell_type":"markdown","id":"BhGmBU7EPcZD","metadata":{"id":"BhGmBU7EPcZD"},"source":[]},{"cell_type":"code","execution_count":15,"id":"NAMMn8W16q4a","metadata":{"id":"NAMMn8W16q4a","executionInfo":{"status":"ok","timestamp":1717351373883,"user_tz":-180,"elapsed":3,"user":{"displayName":"Hilal N. Tek","userId":"15092988536956430744"}}},"outputs":[],"source":["#Load The Dataset"]},{"cell_type":"code","execution_count":16,"id":"AuRWWEeJ6qKK","metadata":{"id":"AuRWWEeJ6qKK","executionInfo":{"status":"ok","timestamp":1717351373883,"user_tz":-180,"elapsed":3,"user":{"displayName":"Hilal N. Tek","userId":"15092988536956430744"}}},"outputs":[],"source":["#train_path = \"/content/drive/MyDrive/datasets/train-v0.1.json\"\n","#eval_path = \"/content/drive/MyDrive/datasets/dev-v0.1.json\""]},{"cell_type":"code","execution_count":17,"id":"q2JsqUcgnowT","metadata":{"id":"q2JsqUcgnowT","executionInfo":{"status":"ok","timestamp":1717351373883,"user_tz":-180,"elapsed":3,"user":{"displayName":"Hilal N. Tek","userId":"15092988536956430744"}}},"outputs":[],"source":["train_path = \"/content/drive/MyDrive/datasets/QA/final_train_data_v2.json\"\n","eval_path = \"/content/drive/MyDrive/datasets/QA/final_dev_data_v2.json\""]},{"cell_type":"code","execution_count":18,"id":"0d1e9da4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26710,"status":"ok","timestamp":1717351400591,"user":{"displayName":"Hilal N. Tek","userId":"15092988536956430744"},"user_tz":-180},"id":"0d1e9da4","outputId":"f708c562-ac47-4a87-d6ac-b698c7fc6444"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of questions:  14221\n"]}],"source":["# Veri kümesini yükleyin ve işleyin\n","json_dataset = read_json(train_path)\n","raw_dataset = json_to_list(json_dataset)\n","\n","# Preprocess data\n","for item in raw_dataset:\n","    item.preprocess()\n","\n","# Girdileri ve hedefleri oluşturun\n","x, y = create_input_targets(raw_dataset)\n","\n","# Eğitim ve test veri setlerini ayırın\n","train_dataset, test_dataset = train_test_split(raw_dataset)\n","x_train, y_train = create_input_targets(train_dataset)\n","x_test, y_test = create_input_targets(test_dataset)"]},{"cell_type":"code","execution_count":19,"id":"MCtfLGjb4vnA","metadata":{"id":"MCtfLGjb4vnA","executionInfo":{"status":"ok","timestamp":1717351400592,"user_tz":-180,"elapsed":16,"user":{"displayName":"Hilal N. Tek","userId":"15092988536956430744"}}},"outputs":[],"source":["#configuration = BertConfig()"]},{"cell_type":"code","execution_count":20,"id":"YtrM1rtpZ0nJ","metadata":{"id":"YtrM1rtpZ0nJ","executionInfo":{"status":"ok","timestamp":1717351400592,"user_tz":-180,"elapsed":15,"user":{"displayName":"Hilal N. Tek","userId":"15092988536956430744"}}},"outputs":[],"source":["#pip install --upgrade tensorflow transformers"]},{"cell_type":"code","execution_count":21,"id":"u9DYpzliQwhk","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6581,"status":"ok","timestamp":1717351407158,"user":{"displayName":"Hilal N. Tek","userId":"15092988536956430744"},"user_tz":-180},"id":"u9DYpzliQwhk","outputId":"8e45f4f0-88f6-4767-caee-429d05c79c56"},"outputs":[{"output_type":"stream","name":"stdout","text":["All TPU devices:  [LogicalDevice(name='/device:TPU:0', device_type='TPU'), LogicalDevice(name='/device:TPU:1', device_type='TPU'), LogicalDevice(name='/device:TPU:2', device_type='TPU'), LogicalDevice(name='/device:TPU:3', device_type='TPU'), LogicalDevice(name='/device:TPU:4', device_type='TPU'), LogicalDevice(name='/device:TPU:5', device_type='TPU'), LogicalDevice(name='/device:TPU:6', device_type='TPU'), LogicalDevice(name='/device:TPU:7', device_type='TPU')]\n"]}],"source":["print(\"All TPU devices: \", tf.config.list_logical_devices('TPU'))"]},{"cell_type":"code","execution_count":22,"id":"a_qiUsYG44Rf","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["326231fae9e9456e96b1a3ca81d8cd07","b29d5d7a156d4dfeb5a54f709b0fa50d","1c7e7b6fa1e745beab6ff3307bcfa2ed","03ae136ce4b6495ab126802c6bec2545","009751eee6f44f958372d99defa8ac87","6b0e0894b3f541acbe0a17a6409e2e10","353fd2cd76a4471a8aebe7e52d82cd15","878bfd19cfde48989a391058e16e3e7b","90198f59f2ab48d98956fc150b0c214e","b8e56bf5a8884ba28551cd9c8db13a22","2cce363726c546d9b9e3a78d886977b3"]},"executionInfo":{"elapsed":48985,"status":"ok","timestamp":1717351456560,"user":{"displayName":"Hilal N. Tek","userId":"15092988536956430744"},"user_tz":-180},"id":"a_qiUsYG44Rf","outputId":"63d2f54d-ffd5-43d9-d945-1964197c3228"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running on TPU  \n"]},{"output_type":"display_data","data":{"text/plain":["tf_model.h5:   0%|          | 0.00/545M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"326231fae9e9456e96b1a3ca81d8cd07"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at dbmdz/bert-base-turkish-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at dbmdz/bert-base-turkish-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_ids (InputLayer)      [(None, 512)]                0         []                            \n","                                                                                                  \n"," attention_mask (InputLayer  [(None, 512)]                0         []                            \n"," )                                                                                                \n","                                                                                                  \n"," token_type_ids (InputLayer  [(None, 512)]                0         []                            \n"," )                                                                                                \n","                                                                                                  \n"," tf_bert_model (TFBertModel  TFBaseModelOutputWithPooli   1106173   ['input_ids[0][0]',           \n"," )                           ngAndCrossAttentions(last_   44         'attention_mask[0][0]',      \n","                             hidden_state=(None, 512, 7              'token_type_ids[0][0]']      \n","                             68),                                                                 \n","                              pooler_output=(None, 768)                                           \n","                             , past_key_values=None, hi                                           \n","                             dden_states=((None, 512, 7                                           \n","                             68),                                                                 \n","                              (None, 512, 768),                                                   \n","                              (None, 512, 768),                                                   \n","                              (None, 512, 768),                                                   \n","                              (None, 512, 768),                                                   \n","                              (None, 512, 768),                                                   \n","                              (None, 512, 768),                                                   \n","                              (None, 512, 768),                                                   \n","                              (None, 512, 768),                                                   \n","                              (None, 512, 768),                                                   \n","                              (None, 512, 768),                                                   \n","                              (None, 512, 768),                                                   \n","                              (None, 512, 768)),                                                  \n","                              attentions=((None, 12, No                                           \n","                             ne, 512),                                                            \n","                              (None, 12, None, 512),                                              \n","                              (None, 12, None, 512),                                              \n","                              (None, 12, None, 512),                                              \n","                              (None, 12, None, 512),                                              \n","                              (None, 12, None, 512),                                              \n","                              (None, 12, None, 512),                                              \n","                              (None, 12, None, 512),                                              \n","                              (None, 12, None, 512),                                              \n","                              (None, 12, None, 512),                                              \n","                              (None, 12, None, 512),                                              \n","                              (None, 12, None, 512)),                                             \n","                              cross_attentions=None)                                              \n","                                                                                                  \n"," start_logit (Dense)         (None, 512, 1)               768       ['tf_bert_model[0][25]']      \n","                                                                                                  \n"," end_logit (Dense)           (None, 512, 1)               768       ['tf_bert_model[0][25]']      \n","                                                                                                  \n"," flatten (Flatten)           (None, 512)                  0         ['start_logit[0][0]']         \n","                                                                                                  \n"," flatten_1 (Flatten)         (None, 512)                  0         ['end_logit[0][0]']           \n","                                                                                                  \n"," start_probs (Activation)    (None, 512)                  0         ['flatten[0][0]']             \n","                                                                                                  \n"," end_probs (Activation)      (None, 512)                  0         ['flatten_1[0][0]']           \n","                                                                                                  \n","==================================================================================================\n","Total params: 110618880 (421.98 MB)\n","Trainable params: 110618880 (421.98 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n"]}],"source":["use_tpu = True\n","if use_tpu:\n","    try:\n","        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","        print('Running on TPU ', tpu.master())\n","        tf.config.experimental_connect_to_cluster(tpu)\n","        tf.tpu.experimental.initialize_tpu_system(tpu)\n","        strategy = tf.distribute.TPUStrategy(tpu)\n","    except ValueError as e:\n","        print(\"TPU'ya bağlanılamadı:\", e)\n","        print(\"Alternatif kaynağa geçiliyor...\")\n","        use_tpu = False\n","\n","    if use_tpu:\n","        with strategy.scope():\n","            model = create_model()\n","else:\n","    model = create_model()\n","\n","if not use_tpu:\n","    model = create_model()\n","\n","model.summary()"]},{"cell_type":"code","execution_count":23,"id":"64uG6d8u0pi9","metadata":{"id":"64uG6d8u0pi9","executionInfo":{"status":"ok","timestamp":1717351456560,"user_tz":-180,"elapsed":14,"user":{"displayName":"Hilal N. Tek","userId":"15092988536956430744"}}},"outputs":[],"source":["from sklearn.metrics import f1_score, accuracy_score\n","import numpy as np\n","\n","def compute_exact(a_gold, a_pred):\n","    return int(a_gold == a_pred)\n","\n","def evaluate(model, x_test, y_test):\n","    y_pred = model.predict(x_test)\n","    start_preds = np.argmax(y_pred[0], axis=1)\n","    end_preds = np.argmax(y_pred[1], axis=1)\n","    start_true = y_test[0]\n","    end_true = y_test[1]\n","\n","    exact_match = []\n","    f1_scores = []\n","\n","    for i in range(len(start_true)):\n","        pred_ans = (start_preds[i], end_preds[i])\n","        true_ans = (start_true[i], end_true[i])\n","\n","        exact_match.append(compute_exact(pred_ans, true_ans))\n","\n","        # Calculate F1 Score\n","        pred_start, pred_end = pred_ans\n","        true_start, true_end = true_ans\n","\n","        pred_tokens = set(range(pred_start, pred_end + 1))\n","        true_tokens = set(range(true_start, true_end + 1))\n","\n","        common_tokens = pred_tokens.intersection(true_tokens)\n","        if len(common_tokens) == 0:\n","            f1 = 0\n","        else:\n","            precision = len(common_tokens) / len(pred_tokens)\n","            recall = len(common_tokens) / len(true_tokens)\n","            f1 = 2 * (precision * recall) / (precision + recall)\n","        f1_scores.append(f1)\n","\n","    exact_match_rate = np.mean(exact_match)\n","    avg_f1_score = np.mean(f1_scores)\n","\n","    accuracy = accuracy_score(start_true, start_preds) * 0.5 + accuracy_score(end_true, end_preds) * 0.5\n","\n","    print(\"Exact Match: {:.4f}\".format(exact_match_rate))\n","    print(\"F1 Score: {:.4f}\".format(avg_f1_score))\n","    print(\"Accuracy: {:.4f}\".format(accuracy))\n","\n","    return exact_match_rate, avg_f1_score, accuracy"]},{"cell_type":"code","execution_count":24,"id":"tD5XlDsR8eHZ","metadata":{"id":"tD5XlDsR8eHZ","executionInfo":{"status":"ok","timestamp":1717351456560,"user_tz":-180,"elapsed":14,"user":{"displayName":"Hilal N. Tek","userId":"15092988536956430744"}}},"outputs":[],"source":["reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-7)\n","early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, mode='min')"]},{"cell_type":"code","execution_count":27,"id":"wqPUtkur8gRu","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wqPUtkur8gRu","outputId":"37671ee3-8091-4ce2-ef0c-ff4e7a77454c","executionInfo":{"status":"ok","timestamp":1717352362837,"user_tz":-180,"elapsed":288694,"user":{"displayName":"Hilal N. Tek","userId":"15092988536956430744"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","349/349 - 133s - loss: 1.5087 - start_probs_loss: 0.5785 - end_probs_loss: 0.9302 - val_loss: 2.2632 - val_start_probs_loss: 0.9793 - val_end_probs_loss: 1.2839 - lr: 2.0000e-05 - 133s/epoch - 380ms/step\n","Epoch 2/3\n","349/349 - 74s - loss: 1.0326 - start_probs_loss: 0.3782 - end_probs_loss: 0.6543 - val_loss: 2.4698 - val_start_probs_loss: 1.0859 - val_end_probs_loss: 1.3838 - lr: 2.0000e-05 - 74s/epoch - 213ms/step\n","Epoch 3/3\n","349/349 - 69s - loss: 0.7086 - start_probs_loss: 0.2572 - end_probs_loss: 0.4515 - val_loss: 2.7076 - val_start_probs_loss: 1.2089 - val_end_probs_loss: 1.4986 - lr: 2.0000e-05 - 69s/epoch - 199ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7aa04050b610>"]},"metadata":{},"execution_count":27}],"source":["model.fit(\n","    x_train,\n","    y_train,\n","    validation_data=(x_test, y_test),\n","    epochs=3,\n","    verbose=2,\n","    batch_size=32,\n","    callbacks=[reduce_lr, early_stopping, checkpoint],\n",")"]},{"cell_type":"code","execution_count":26,"id":"w5mksYmf-oH7","metadata":{"id":"w5mksYmf-oH7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717352023063,"user_tz":-180,"elapsed":44254,"user":{"displayName":"Hilal N. Tek","userId":"15092988536956430744"}},"outputId":"28e2145f-1734-47dd-f1b0-7eab8642880b"},"outputs":[{"output_type":"stream","name":"stdout","text":["39/39 [==============================] - 42s 243ms/step\n","Exact Match: 0.5698\n","F1 Score: 0.7828\n","Accuracy: 0.7074\n"]},{"output_type":"execute_result","data":{"text/plain":["(0.5698051948051948, 0.7828170218639703, 0.7073863636363635)"]},"metadata":{},"execution_count":26}],"source":["evaluate(model, x_test, y_test)"]},{"cell_type":"code","source":[],"metadata":{"id":"iIUj1Kkf3rJQ","executionInfo":{"status":"ok","timestamp":1717352023064,"user_tz":-180,"elapsed":17,"user":{"displayName":"Hilal N. Tek","userId":"15092988536956430744"}}},"id":"iIUj1Kkf3rJQ","execution_count":26,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"z4pfuDoT3rMW","executionInfo":{"status":"ok","timestamp":1717352023064,"user_tz":-180,"elapsed":16,"user":{"displayName":"Hilal N. Tek","userId":"15092988536956430744"}}},"id":"z4pfuDoT3rMW","execution_count":26,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Y2Hf213j3rPf","executionInfo":{"status":"ok","timestamp":1717352023065,"user_tz":-180,"elapsed":17,"user":{"displayName":"Hilal N. Tek","userId":"15092988536956430744"}}},"id":"Y2Hf213j3rPf","execution_count":26,"outputs":[]},{"cell_type":"markdown","id":"-aLF6akj4_Yz","metadata":{"id":"-aLF6akj4_Yz"},"source":[]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ba3b33c00dd04d2e983a9152108b6a8c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_507d06ed55a64e5fb98624a8b7523a70","IPY_MODEL_9c929c2462e8466e9a999fea6ca40e54","IPY_MODEL_f8536a5e632e46d09d41fb916a0cad6e"],"layout":"IPY_MODEL_a4f68836ba9b48408562a3c94ceba09d"}},"507d06ed55a64e5fb98624a8b7523a70":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3ac059ad8714efa8a84ea6395c498f8","placeholder":"​","style":"IPY_MODEL_dea8ab06d2a846d484ccca592edfe3c5","value":"tokenizer_config.json: 100%"}},"9c929c2462e8466e9a999fea6ca40e54":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9964e4530dbf4fd1a537263b39c4e2ca","max":60,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5892465d7b0142ccabe58cb7391eea61","value":60}},"f8536a5e632e46d09d41fb916a0cad6e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_35ff775f9a2c4c698ca0dbb36b7c693d","placeholder":"​","style":"IPY_MODEL_b595a422ad1b476a9460a5c6e735f40b","value":" 60.0/60.0 [00:00&lt;00:00, 5.22kB/s]"}},"a4f68836ba9b48408562a3c94ceba09d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3ac059ad8714efa8a84ea6395c498f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dea8ab06d2a846d484ccca592edfe3c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9964e4530dbf4fd1a537263b39c4e2ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5892465d7b0142ccabe58cb7391eea61":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"35ff775f9a2c4c698ca0dbb36b7c693d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b595a422ad1b476a9460a5c6e735f40b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6740faa7bc0041f4ac89c0b9ace4fc5d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_561a731a9fb544ebb0102d5bb3e75e1e","IPY_MODEL_8d8e0588bf2640b4b656bb5abadc5cfd","IPY_MODEL_46ab5f1e94c04e89a72ed4cf422323d0"],"layout":"IPY_MODEL_a7f83b2252314695bb371e6d30b1701d"}},"561a731a9fb544ebb0102d5bb3e75e1e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c95b4d13827245ddbe885507f1b0e157","placeholder":"​","style":"IPY_MODEL_88db124de63544ec9671fd854bd350e6","value":"vocab.txt: 100%"}},"8d8e0588bf2640b4b656bb5abadc5cfd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_17d3ee5d34b84f0f8656263af6c2ae86","max":251003,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a007fa5bfc09404ab77dedf08c0bca39","value":251003}},"46ab5f1e94c04e89a72ed4cf422323d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fa78b6c719148549710c465861cf865","placeholder":"​","style":"IPY_MODEL_427bd2ad174e42ee863c0fb03682fe7f","value":" 251k/251k [00:00&lt;00:00, 5.22MB/s]"}},"a7f83b2252314695bb371e6d30b1701d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c95b4d13827245ddbe885507f1b0e157":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88db124de63544ec9671fd854bd350e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"17d3ee5d34b84f0f8656263af6c2ae86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a007fa5bfc09404ab77dedf08c0bca39":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1fa78b6c719148549710c465861cf865":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"427bd2ad174e42ee863c0fb03682fe7f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2293dbab60144a04a8471fc814b2d018":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_041157f9e4184cb5a6f04b557e63f733","IPY_MODEL_3069157f38014d738501c28834d3e086","IPY_MODEL_09017577a81048ddac414233ee56cdd6"],"layout":"IPY_MODEL_9fdf5023acb547f9817b25daa0c0e750"}},"041157f9e4184cb5a6f04b557e63f733":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ff68601bdc0473f92775e6675ab569e","placeholder":"​","style":"IPY_MODEL_ecd86967ac83449382989de1b30336db","value":"config.json: 100%"}},"3069157f38014d738501c28834d3e086":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_07612acc65374780b039050ef97ff343","max":385,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fe45a6767aa547acab9d60c74361a8a0","value":385}},"09017577a81048ddac414233ee56cdd6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5639b3906dbc464b91b176bf4ed55d63","placeholder":"​","style":"IPY_MODEL_37f9a36ab7514a519328085174b8dafa","value":" 385/385 [00:00&lt;00:00, 39.4kB/s]"}},"9fdf5023acb547f9817b25daa0c0e750":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ff68601bdc0473f92775e6675ab569e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ecd86967ac83449382989de1b30336db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"07612acc65374780b039050ef97ff343":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe45a6767aa547acab9d60c74361a8a0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5639b3906dbc464b91b176bf4ed55d63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37f9a36ab7514a519328085174b8dafa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"326231fae9e9456e96b1a3ca81d8cd07":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b29d5d7a156d4dfeb5a54f709b0fa50d","IPY_MODEL_1c7e7b6fa1e745beab6ff3307bcfa2ed","IPY_MODEL_03ae136ce4b6495ab126802c6bec2545"],"layout":"IPY_MODEL_009751eee6f44f958372d99defa8ac87"}},"b29d5d7a156d4dfeb5a54f709b0fa50d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b0e0894b3f541acbe0a17a6409e2e10","placeholder":"​","style":"IPY_MODEL_353fd2cd76a4471a8aebe7e52d82cd15","value":"tf_model.h5: 100%"}},"1c7e7b6fa1e745beab6ff3307bcfa2ed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_878bfd19cfde48989a391058e16e3e7b","max":545150592,"min":0,"orientation":"horizontal","style":"IPY_MODEL_90198f59f2ab48d98956fc150b0c214e","value":545150592}},"03ae136ce4b6495ab126802c6bec2545":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8e56bf5a8884ba28551cd9c8db13a22","placeholder":"​","style":"IPY_MODEL_2cce363726c546d9b9e3a78d886977b3","value":" 545M/545M [00:03&lt;00:00, 194MB/s]"}},"009751eee6f44f958372d99defa8ac87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b0e0894b3f541acbe0a17a6409e2e10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"353fd2cd76a4471a8aebe7e52d82cd15":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"878bfd19cfde48989a391058e16e3e7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90198f59f2ab48d98956fc150b0c214e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b8e56bf5a8884ba28551cd9c8db13a22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cce363726c546d9b9e3a78d886977b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}